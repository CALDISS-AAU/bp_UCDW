---
title: "WP1 Analyser"
author: "CALDISS"
format:
  revealjs: 
    theme: [simple, custom.scss]
execute: 
  echo: false
  error: false
  warning: false
editor: visual
project:
  execute-dir: project
---

```{r setup}
#| output: false

#install.packages(c('tidyverse', 'knitr', 'jsonlite', 'gt', 'gtsummary', 'patchwork', 'wordcloud', 'wordcloud2', 'ggrepel', 'ggplot2', 'extrafont'))

library(tidyverse)
library(knitr)
library(ggplot2)
library(jsonlite)
library(gt)
library(gtsummary)
library(scales)
library(patchwork)
library(wordcloud)
library(wordcloud2)
library(ggrepel)

extrafont::loadfonts(quiet = TRUE)

#setwd('/work/UCDW')
setwd('/work/ucdw')

## text data
convos_df <- read_csv('data/work/bv_convos_all.csv')

## keywords
keyws_data <- read_csv('output/for_presentation/word_count.csv')

## topics
topic_df <- read_csv('output/for_presentation/OG_data_plus_topics.csv')

## plot data
jac_ind <- read_csv('output/embeddings/jaccard_indices.csv')
jac_sum <- read_csv('output/embeddings/jaccard_summary_statistics.csv')
keyws_proj <- read_csv('output/embeddings/keyword_projections.csv')
keyws_compare <- read_csv('output/embeddings/plotting_data_keywords_compare_gender.csv')

## corpus
corpus_all <- fromJSON('data/work/we_corpus/tokenized_corpus_all.json')
corpus_female <- fromJSON('data/work/we_corpus/tokenized_corpus_female.json')
corpus_male <- fromJSON('data/work/we_corpus/tokenized_corpus_male.json')

## theme
theme_use <- theme_minimal(base_family = "serif",
                           base_size = 15)

```

```{r handling}

# data handling
convos_df <- convos_df |>
  mutate(requester_age = as.numeric(str_extract(requester_age_name, '\\d+')),
         gender = case_match(
           requester_gender_name,
           c('Dreng', 'Ung mand') ~ 'male',
           c('Pige', 'Ung kvinde') ~ 'female',
           c('Ukendt', 'Ønsker ikke oplyse køn', 'Ønsker ikke at oplyse', 'Anden kønsidentitet') ~ 'other'
         ),
         requester_age = ifelse(is.na(requester_age), 
                                requester_age_selfreported, 
                                requester_age),
         gender = case_match(
           requester_gender_selfreported,
           'Dreng' ~ 'male',
           c('Pige', 'Ung kvinde') ~ 'female',
           .default = gender
         ),
         gender = ifelse(is.na(gender), 'other', gender)) |> 
  filter(!(is_fast_bruger),
         #requester_channel != 'letter', 
         is_incoming, 
         !(is.na(message))) |> 
  filter(requester_age %in% c(10:16))

# combine chats
convos_g_df <- convos_df |> 
  group_by(conversation_code) %>%
  summarise(
    chat = str_c(message, collapse = ". "),
    .groups = "drop"
  ) |> 
  left_join(select(convos_df, conversation_code, requester_age, 
                   gender, last_contact_dt, requester_channel), 
            by = 'conversation_code', multiple = 'first')

```

```{r handlekw}

wildcards <- c('ærlig', 'år', 'altså', 'går', 'ik', 'sker', 'generelt', 'komme', 'begynde', 'besked', 'dreng \\d+', 'pige \\d+', 'egentlig', 'loc', 'måned', 'uge', 'snart')

wildcards_pattern <- str_c(wildcards, collapse = "|")

strips <- c('^bare', '^fik', '^når')

strips_p <- str_c(strips, collapse = "|")

verbatims <- c('åbenbart', 'åbent', 'alt', 'ca måneder', 'dagligt', 'desværre', 'efterfølgende', 'fået afvide', 'fået masse', 'fået vide', 'far sagt', 'får sagt', 'fedt', 'fjerne', 'fjernet', 'here', 'hey', 'hi', 'hmm', 'holdt', 'hører', 'hov', 'idk', 'især når', 'me', 'mhm', 'næ', 'of', 'oh', 'øhm', 'org', 'osv føler', 'præcist', 'sendt', 'sidste to', 'that', 'this', 'vel prøve', 'with')


keyws_use <- keyws_data |> 
  select(word, count) |> 
  filter(!(word %in% verbatims),
         !(str_detect(word, wildcards_pattern))) |> 
  mutate(word = str_replace(word, strips_p, "")) |> 
  distinct(word) |> 
  pull(word)
```

```{r handletopics}

topic_df_g <- topic_df |> 
  left_join(select(convos_df, conversation_code, requester_channel), 
            by = c("id" = "conversation_code"),
            multiple = "first") |> 
  mutate(
    requester_channel = ifelse(
      is.na(requester_channel), 
      "interview", 
      requester_channel)) |> 
  filter(topic != -1) |> 
  group_by(topic, requester_channel) |> 
  count() |> 
  ungroup() |> 
  group_by(requester_channel) |> 
  mutate(pct = n / sum(n))
```

## Hvad har vi lavet?

:::: {.columns}

::: {.column width="50%"}

**Foreløbig emneanalyse**

-   Vi kan umiddelbart se, at tematikker varierer på tværs af platforme

-   Analysemodel skal finjusteres yderligere for at udlede meningsfulde emner

:::

::: {.column width="50%"}

**Simple word embeddings**

-   Vi har modeller for hhv. drenge og piger, som vi kan udforske semantiske relationer i

-   Indtil videre undersøgt forskel ved brug af specifikke trivsels-relaterede nøgleord

-   Resultater er lige nu ikke pålidelige; sårbare over for små ændringer i data

:::

::::

## Om data


:::: {.columns}

::: {.column width="50%"}

-   Samtaledata (chat + sms), brevkasse og fem fokusgruppeinterviews

-   Beskrivende statistikker dækker samtale- og brevkassedata

:::

::: {.column width="50%"}

```{r desc}

summaries <- convos_g_df |> 
  summarise(total_chats = n(),
            total_tokens = sum(str_count(chat, "\\S+")),
            mean_chat_length = mean(str_count(chat, "\\S+")),
            first_chat = as.Date(min(last_contact_dt, na.rm = TRUE)),
            last_chat = as.Date(max(last_contact_dt, na.rm = TRUE)))
  

# Build summary table
summary_tbl <- tibble(
  Summary = c(
    "Antal chats",
    "Total antal tokens",
    "Gns. antal tokens per chat",
    "Dato for første chat",
    "Dato for sidste chat"
  ),
  Value = c(
    formatC(summaries$total_chats[1], format = "d", big.mark = ".", decimal.mark = ","),
    formatC(summaries$total_tokens[1], format = "d", big.mark = ".", decimal.mark = ","),
    formatC(summaries$mean_chat_length[1], format = "f", digits = 2, 
            big.mark = ".", decimal.mark = ","),
    as.character(summaries$first_chat[1]),
    as.character(summaries$last_chat[1])
  )
)

# Format with gt and custom number formatting
summary_tbl |>
  gt() |>
  opt_table_font(
    font = list("serif")) |> 
  cols_label(
    Summary = "",
    Value = ""
  ) |> 
  tab_header(title = "Beskrivende statistikker")

```

:::

::::



## Fordeling af data

```{r descplots}

p1 <- convos_g_df |> 
  count(requester_channel) |> 
  mutate(pct = n/sum(n)) |> 
  ggplot(aes(x = requester_channel, y = pct)) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Kanal", 
       y = "Procent", 
       title = "Fordeling af samtaler over kanaler") + 
  theme_use

p2 <- convos_g_df |> 
  mutate(gender = case_match(
    gender,
    "male" ~ "Dreng",
    "female" ~ "Pige",
    "other" ~ "Andet eller uoplyst køn"
  )) |> 
  count(gender) |> 
  mutate(pct = n/sum(n)) |> 
  ggplot(aes(x = gender, y = pct)) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Køn", 
       y = "Procent", 
       title = "Fordeling af samtaler over køn") +
  theme_use

p3 <- convos_g_df |> 
  count(requester_age) |> 
  mutate(pct = n/sum(n)) |> 
  ggplot(aes(x = requester_age, y = pct)) + 
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_continuous(breaks = c(10:16), labels = c(10:16)) + 
  labs(x = "Alder", 
       y = "Procent", 
       title = "Fordeling af samtaler over alder") +
  theme_use

combined <- (p1 + p2) / p3

combined +
  theme_use

```

## Emneanalyse - baggrund

-   Samtale-, brevkasse- og interviewdata inddelt i lige store tekststykker (ca. 150 tegn)

-   Data filtreret til alder 10-16 samt frasorterer faste brugere

-   *For samtaledata:*

    -   Indeholder kun brugerens svar

    -   Meget korte beskeder frasorteret ("hej", "nej", osv.)

-   Brug af eksisterende sprogmodel ("sentence transformer") til at konvertere tekststykker til numerisk repræsentation med samme dimensionalitet

    -   Alle tekststykker repræsenteret ved 1024 tal

-   Brug af klyngeanalyse (HDBSCAN) til at gruppere tekststykker efter lignende indhold

-   Returnerer ca. 120-140 emner - skal reduceres yderligere

-   Nøgleord udledt på tværs af emner som de ord, der kendetegner de forskellige emner

## Nøgleord på tværs af data

```{r viskeyws}

#wordcloud(words = keyws_use, 
#          freq = rep(1, length(keyws_use)), 
#          min.freq = 1, 
#          random.order = FALSE,
#          rot.per = 0, 
#          scale = c(0.4, 0.4))

p <- wordcloud2(data = data.frame(word = keyws_use, 
                             freq = rep(1, length(keyws_use))),
           size = 0.1,
           fontWeight = 'normal', 
           shuffle = FALSE)

```
![](topic-keyws_wordcloud.png)

## Fordeling af emner på tværs af kanaler

```{r topicvis}

topic_df_g |> 
  mutate(requester_channel = factor(case_match(
    requester_channel,
    "interview" ~ "Interview",
    "letter" ~ "Brevkasse",
    "sms" ~ "SMS",
    "webchat" ~ "Webchat"
  ), levels = c("Brevkasse", "SMS", "Webchat", "Interview"))) |> 
  ggplot(aes(x = topic, y = pct, fill = requester_channel)) +
    geom_bar(stat = 'identity') + 
    scale_y_continuous(limits = c(0, 0.075), labels = percent) + 
    facet_wrap(~requester_channel) + 
    labs(x = "Emner", y = "Pct. af data",
         caption = "Note: Ét topic ekskluderet, som indfanger 40% af interviewdata") +
    guides(fill = "none") + 
    theme_use + 
    theme(plot.caption = element_text(hjust = 1, face = "italic", color = "darkred"))

```

## Emneanalyse - videre arbejde

-   Emneanalysen giver meningsfulde emner, som kan arbejdes videre med

-   Der skal arbejdes videre med emnerne før at de er brugbare

-   Der er indikationer af, at emner varierer på tværs af kanaler

# Embedding modeller

## Data brugt til embedding modeller

:::: {.columns}

::: {.column width="50%"}

-   Bruger kun chat og sms
-   Data filtreret til alder 10-16 samt frasorterer faste brugere
-   Bruger kun beskeder fra brugeren
-   "Tokenization": Opdeling i enkeltord
    -   Fjerne tegnsætning
    -   Konvertere til ordstamme
    -   Udelade stopord
-   Tre modeller: alle, drenge, piger

:::

::: {.column width="50%"}


```{r embedtokens}

# Build summary table
summary_tbl_emb <- tibble(
  Summary = c(
    "Total antal tokens",
    "Antal tokens efter filtrering",
    "Antal tokens - Drenge",
    "Antal tokens - Piger"
    ),
  Value = c(
    formatC(summaries$total_tokens[1], format = "d", big.mark = ".", decimal.mark = ","),
    formatC(sum(lengths(corpus_all)), format = "d", big.mark = ".", decimal.mark = ","),
    formatC(sum(lengths(corpus_male)), format = "d", big.mark = ".", decimal.mark = ","),
    formatC(sum(lengths(corpus_female)), format = "d", big.mark = ".", decimal.mark = ",")
  )
)

# Format with gt and custom number formatting
summary_tbl_emb |>
  gt() |>
  opt_table_font(
    font = list("serif")) |> 
  cols_label(
    Summary = "",
    Value = ""
  ) |> 
  tab_header(title = "Data til embedding modeller")


```

:::

::::

## Embedding modeller - baggrund

-   For hvert ord forsøger modellen at prædiktere, hvilke ord, der kommer rundt om det

-   Kigger på 10 ord på hver side (OBS: tokenization - gør faktisk kontekst større)

-   Resultatet bliver en række vægte for hvert ord, der afspejler den kontekst, som ordet optræder i

    -   Hvert ord tildelt 100 vægte/tal

    -   Ord med lignende vægte tolkes typisk som ord, som semantisk minder om hinanden (optræder i lignende kontekster)

-   *Modellerne testet på to måder:*

    -   Afstand mellem nøgleord: Med udgangspunkt i en række trivsels-relaterede nøgleord, udregn hvor langt disse er fra hinanden i hver af de tre modeller (jo længere fra hinanden, jo mere forskellige)

    -   Mest lignende ord: Med udgangspunkt i en række trivsels-relaterede nøgleord, finde de fem mest lignende ord for hvert nøgleord i hver model

## Semantiske relationer

```{r vizkeyem}

keyws_proj |> 
  mutate(type = case_match(
    model, 
    "model_a" ~ "Al materiale",
    "model_f" ~ "Piger",
    "model_m" ~ "Drenge"
  )) |> 
  ggplot(aes(x = x, y = y, label = keyword, colour = type)) + 
  geom_point(size = 0.5) + 
  geom_text(nudge_y = 0.1) + 
  scale_colour_brewer(type = "qual", palette = "Dark2") + 
  labs(colour = "") + 
  theme_use

```

## Kønsforskelle

```{r vizembedgen}

keyws_compare_use <- keyws_compare |> 
  mutate(type = case_match(
    model, 
    "keyword" ~ "Keyword",
    "model_f" ~ "Piger",
    "model_m" ~ "Drenge"
  ))

ggplot(keyws_compare_use) + 
  geom_point(aes(x=x, y=y, color = type), size=0.5, alpha=0.9) + 
  geom_text(
        data=filter(keyws_compare_use, is_keyword == TRUE),
        mapping=aes(label=word, x=x, y=y),
        size=3.5) + 
    geom_text_repel(
        data=filter(keyws_compare_use, is_keyword == FALSE),
        mapping=aes(label=word, x=x, y=y, color=type), 
        size=3,
        max.overlaps = 15) + 
  scale_colour_brewer(type = "qual", palette = "Dark2") + 
  scale_y_continuous(breaks = seq(0,8, by = 0.5)) + 
  scale_x_continuous(limits = c(-0.4, 0.4)) + 
  geom_vline(xintercept=0, linetype='dashed', color='gray') +
  labs(colour = "") + 
  theme_use + 
  theme(base_size = 10)
```

## Modelvalidering - baggrund

-   Normalt evalueres modeller ud fra, hvorvidt de indfanger "forventede" semantiske relationer (kræver valideringsdata)

-   Givet vores formål med data, har vi ikke meningsfuld evalueringsdata

-   Modeller i stedet valideret ud fra, hvor pålidelige resultaterne er

-   *Brug af krydsvalidering*:

    -   Træn 10 modeller, hvor 10% af data udelades (hvilke 10% skifter)

    -   For hver trænet model, udled de fem mest lignende ord fra otte trivsels-relaterede nøgleord

        -   'glad', 'bange', 'høre', 'ven', 'vendinde', 'hjem', 'skole', 'klasse'

    -   Sammenlign overlap mellem sæt af ord fundet mellem modeller

        -   Brug af Jaccard index: 0 = ingen overlap, 1 = total overlap

-   Validering fortæller os, hvor robuste resultaterne er. Hvis robuste, bør samme relationer genfindes (altså højt overlap mellem sæt af ord fundet med modellerne)

## Modelvalidering

-   Modeller har generelt lavt gennemsnitligt Jaccard index

-   Vidner om, at fundne ord varierer meget fra model til model, når dele af data udelades

```{r vizmodeleval}

jac_ind |> 
  mutate(type = case_match(
    model, 
    "all" ~ "Al materiale",
    "female" ~ "Piger",
    "male" ~ "Drenge"
  )) |> 
  ggplot(aes(x = jaccard_index, fill = type)) + 
  geom_boxplot() + 
  coord_flip() + 
  labs(x = "Jaccard Index (overlap mellem ordsæt)", fill = "") + 
  scale_fill_brewer(type = "qual", palette = "Dark2") + 
  theme_use + 
  theme(axis.text.x = element_blank(),   
        axis.ticks.x = element_blank(),  
        axis.title.x = element_blank())
```

## Hvad nu?

**Emneanalyse**

-   Hvis relevant for ansøgningen, skal emner finjusteres yderligere, så vi kan bruge dem meningsfuldt i en form for indledende analyse

**Embeddingmodeller**

-   Indtil videre bekræftes, at metoden virker

-   Dog skal modellerne forbedres: mere data eller anden tilgang til træning (fx bygge oven på eksisterende model)

-   Yderligere træning/justering kræver ressourcer: data og tid - Kan være et argument, der kan fremhænves i ansøgning
